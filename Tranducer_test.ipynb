{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ab8350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n",
      "The torchaudio backend is switched to 'soundfile'. Note that 'sox_io' is not supported on Windows.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "\n",
    "import string\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import unidecode\n",
    "import speechbrain\n",
    "from speechbrain.nnet.loss.transducer_loss import TransducerLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de21d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librispeech的数据可以通过torchaudio去简单的导入\n",
    "#SpeechData_Train = torchaudio.datasets.LIBRISPEECH('./data', 'train-clean-100', 'LibriSpeech', False)\n",
    "#(tensor([[-0.0033,  0.0000,  0.0003,  ...,  0.0056,  0.0054,  0.0055]]), 16000, 'PETER HAD ASKED HIM OF COURSE FOR MATTHEW CUTHBERT HAD NEVER BEEN KNOWN TO VOLUNTEER INFORMATION ABOUT ANYTHING IN HIS WHOLE LIFE AND YET HERE WAS MATTHEW CUTHBERT AT HALF PAST THREE ON THE AFTERNOON OF A BUSY DAY PLACIDLY DRIVING OVER THE HOLLOW AND UP THE HILL', 103, 1240, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e49c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label ='#abcdefghijklmnopqrstuvwxyz\\' '，其中‘#’在这里也解释为NULL（空）\n",
    "#spectrogram = torchaudio.transforms.MFCC()\n",
    "#train_sets = []\n",
    "#test_sets = []\n",
    "#for _ ,a in enumerate(SpeechData_Train):\n",
    "#    speech_signal = spectrogram(a[0]) #speech tensor\n",
    "#    speech_sets.append(speech_signal)\n",
    "#    text_signal = a[2].lower()\n",
    "#    text_tensor = []\n",
    "#    for i in text_signal:\n",
    "#        if i not in label:\n",
    "#            print(i)\n",
    "#        text_tensor.append(label.index(i))\n",
    "#    text_tensor = torch.Tensor(text_tensor).long()\n",
    "#    text_sets.append(text_tensor)\n",
    "#torch.save(speech_sets,'./speech_sets.pth')\n",
    "#torch.save(text_sets,'./text_sets.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f32bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#预先处理好的音频特征和文本数据\n",
    "speech_sets = torch.load('./speech_sets.pth')\n",
    "text_sets = torch.load('./text_sets.pth')\n",
    "NULL_INDEX = 0 #起始字符、空字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2be654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建编码器 LAS金字塔式encoder\n",
    "#将语音信号编码成一个固定大小的向量\n",
    "#embed_size:mfcc的维度，为40\n",
    "#num_hiddens:上下文向量的维度\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embed_size, num_hiddens, num_layers, dropout = 0, **kwargs):\n",
    "        super(Encoder,self).__init__(**kwargs)\n",
    "        self.embed_size = embed_size\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.rnn1 = nn.GRU(embed_size, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.rnn2 = nn.GRU(2*num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.rnn3 = nn.GRU(2*num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(num_hiddens, num_hiddens)\n",
    "        \n",
    "    def forward(self, signal_mfcc):\n",
    "        batch_size = signal_mfcc.shape[0]\n",
    "        signal_mfcc = signal_mfcc.permute(1,0,2)\n",
    "        output,state= self.rnn1(signal_mfcc)\n",
    "        if len(output)%2 == 0:\n",
    "            output = output.permute(1,0,2).reshape(batch_size,-1,2*self.num_hiddens)\n",
    "        else:\n",
    "            padding_matrix = torch.zeros(batch_size,self.num_hiddens).unsqueeze(dim = 1).to(signal_mfcc.device)\n",
    "            output = torch.cat((output.permute(1,0,2),padding_matrix),dim = 1).reshape(batch_size,-1,2*self.num_hiddens)\n",
    "        output = output.permute(1,0,2)\n",
    "        output, state = self.rnn2(output)\n",
    "        if len(output)%2 == 0:\n",
    "            output = output.permute(1,0,2).reshape(batch_size,-1,2*self.num_hiddens)\n",
    "        else:\n",
    "            padding_matrix = torch.zeros(batch_size,self.num_hiddens).unsqueeze(dim = 1).to(signal_mfcc.device)\n",
    "            output = torch.cat((output.permute(1,0,2),padding_matrix),dim = 1).reshape(batch_size,-1,2*self.num_hiddens)\n",
    "        output = output.permute(1,0,2)\n",
    "        output, state = self.rnn3(output)\n",
    "        return (output,state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c980e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#预测器\n",
    "class Predictor(torch.nn.Module):\n",
    "    def __init__(self, num_outputs, predictor_dim, joiner_dim, NULL_INDEX):\n",
    "        super(Predictor, self).__init__()\n",
    "        self.embed = torch.nn.Embedding(num_outputs, predictor_dim)\n",
    "        self.rnn = torch.nn.GRUCell(input_size=predictor_dim, hidden_size=predictor_dim)\n",
    "        self.linear = torch.nn.Linear(predictor_dim, joiner_dim)\n",
    "    \n",
    "        self.initial_state = torch.nn.Parameter(torch.randn(predictor_dim))\n",
    "        self.start_symbol = NULL_INDEX # In the original paper, a vector of 0s is used; just using the null index instead is easier when using an Embedding layer.\n",
    "\n",
    "    def forward_one_step(self, input, previous_state):\n",
    "        embedding = self.embed(input)\n",
    "        state = self.rnn.forward(embedding, previous_state)\n",
    "        out = self.linear(state)\n",
    "        return out, state\n",
    "\n",
    "    def forward(self, y):\n",
    "        batch_size = y.shape[0]\n",
    "        U = y.shape[1]\n",
    "        outs = []\n",
    "        state = torch.stack([self.initial_state] * batch_size).to(y.device)\n",
    "        for u in range(U+1): # need U+1 to get null output for final timestep \n",
    "            if u == 0:\n",
    "                decoder_input = torch.tensor([self.start_symbol] * batch_size).to(y.device)\n",
    "            else:\n",
    "                decoder_input = y[:,u-1]\n",
    "            out, state = self.forward_one_step(decoder_input, state)\n",
    "            outs.append(out)\n",
    "        out = torch.stack(outs, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7af578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joiner(torch.nn.Module):\n",
    "    def __init__(self, num_outputs, joiner_dim):\n",
    "        super(Joiner, self).__init__()\n",
    "        self.linear = torch.nn.Linear(joiner_dim, num_outputs)\n",
    "\n",
    "    def forward(self, encoder_out, predictor_out):\n",
    "        out = encoder_out + predictor_out\n",
    "        out = torch.nn.functional.relu(out)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bb64a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#将编码器、预测器打包起来\n",
    "class Transducer(torch.nn.Module):\n",
    "    def __init__(self, embed_size, encoder_dim, num_layers, dropout, num_outputs, predictor_dim, joiner_dim, NULL_INDEX):\n",
    "        super(Transducer, self).__init__()\n",
    "        self.encoder = Encoder(embed_size, encoder_dim, num_layers, dropout = dropout)\n",
    "        self.predictor = Predictor(num_outputs, predictor_dim, joiner_dim, NULL_INDEX)\n",
    "        self.joiner = Joiner(num_outputs,joiner_dim)\n",
    "        self.transducer_loss = TransducerLoss(0)\n",
    "\n",
    "        if torch.cuda.is_available(): self.device = \"cuda:0\"\n",
    "        else: self.device = \"cpu\"\n",
    "        self.to(self.device)\n",
    "\n",
    "    def compute_forward_prob(self, joiner_out, T, U, y, NULL_INDEX):\n",
    "        \"\"\"\n",
    "        joiner_out: tensor of shape (B, T_max, U_max+1, #labels)\n",
    "        T: list of input lengths\n",
    "        U: list of output lengths \n",
    "        y: label tensor (B, U_max+1)\n",
    "        \"\"\"\n",
    "        B = joiner_out.shape[0]\n",
    "        T_max = joiner_out.shape[1]\n",
    "        U_max = joiner_out.shape[2] - 1\n",
    "        log_alpha = torch.zeros(B, T_max, U_max+1).to(self.device)\n",
    "        #print(log_alpha.shape)\n",
    "        for t in range(T_max):\n",
    "            for u in range(U_max+1):\n",
    "                if u == 0:\n",
    "                    if t == 0:\n",
    "                        log_alpha[:, t, u] = 0.\n",
    "\n",
    "                    else: #t > 0\n",
    "                        log_alpha[:, t, u] = log_alpha[:, t-1, u] + joiner_out[:, t-1, 0, NULL_INDEX] \n",
    "                  \n",
    "                else: #u > 0\n",
    "                    if t == 0:\n",
    "                        log_alpha[:, t, u] = log_alpha[:, t,u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
    "            \n",
    "                    else: #t > 0\n",
    "                        log_alpha[:, t, u] = torch.logsumexp(torch.stack([\n",
    "                            log_alpha[:, t-1, u] + joiner_out[:, t-1, u, NULL_INDEX],\n",
    "                            log_alpha[:, t, u-1] + torch.gather(joiner_out[:, t, u-1], dim=1, index=y[:,u-1].view(-1,1) ).reshape(-1)\n",
    "                        ]), dim=0)\n",
    "    \n",
    "        log_probs = []\n",
    "        for b in range(B):\n",
    "            log_prob = log_alpha[b, T[b]-1, U[b]] + joiner_out[b, T[b]-1, U[b], NULL_INDEX]\n",
    "            log_probs.append(log_prob)\n",
    "        log_probs = torch.stack(log_probs) \n",
    "        return log_prob\n",
    "\n",
    "    def compute_loss(self, x, y, T, U,NULL_INDEX):\n",
    "        encoder_out = self.encoder.forward(x)[0].permute(1,0,2)\n",
    "        T = T.long()\n",
    "        predictor_out = self.predictor.forward(y)\n",
    "        U = U.long()\n",
    "        joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
    "        loss = -self.compute_forward_prob(joiner_out, T, U, y, NULL_INDEX).mean()\n",
    "        return loss\n",
    "    def greedy_search(self, x, T):\n",
    "        y_batch = []\n",
    "        B = len(x)\n",
    "        encoder_out = self.encoder.forward(x)[0]\n",
    "        U_max = 300\n",
    "        for b in range(B):\n",
    "            t = 0; u = 0; y = [self.predictor.start_symbol]; predictor_state = self.predictor.initial_state.unsqueeze(0)\n",
    "            while t < T[b] and u < U_max:\n",
    "                predictor_input = torch.tensor([ y[-1] ]).to(x.device)\n",
    "                g_u, predictor_state = self.predictor.forward_one_step(predictor_input, predictor_state)\n",
    "                f_t = encoder_out[b, t]\n",
    "                h_t_u = self.joiner.forward(f_t, g_u)\n",
    "                argmax = h_t_u.max(-1)[1].item()\n",
    "                if argmax == NULL_INDEX:\n",
    "                    t += 1\n",
    "                else: # argmax == a label\n",
    "                    u += 1\n",
    "                    y.append(argmax)\n",
    "            y_batch.append(y[1:]) # 去掉首元素\n",
    "        return y_batch\n",
    "    def compute_loss1(self, x, y, T, U):\n",
    "        encoder_out = self.encoder.forward(x)[0].permute(1,0,2)\n",
    "        predictor_out = self.predictor.forward(y)\n",
    "        joiner_out = self.joiner.forward(encoder_out.unsqueeze(2), predictor_out.unsqueeze(1)).log_softmax(3)\n",
    "        #loss = -self.compute_forward_prob(joiner_out, T, U, y).mean()\n",
    "        T = T.to(joiner_out.device)\n",
    "        U = U.to(joiner_out.device)\n",
    "        loss = self.transducer_loss(joiner_out, y, T, U) #, blank_index=NULL_INDEX, reduction=\"mean\")\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f392722",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据处理，构建数据的dataoader\n",
    "class SpeechDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, speech_sets, text_sets, batch_size):\n",
    "        self.length = len(speech_sets)\n",
    "        self.SpeechSets = speech_sets\n",
    "        self.TextSets = text_sets\n",
    "        collate = Collate()\n",
    "        self.loader = torch.utils.data.DataLoader(self, batch_size=batch_size, shuffle=False, collate_fn=collate)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.SpeechSets[idx]\n",
    "        y = self.TextSets[idx]\n",
    "        \n",
    "        return (x.squeeze(dim = 0).permute(1,0), y)\n",
    "    \n",
    "class Collate:\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"\n",
    "        batch: list of tuples (input string, output string)[T,Mel_dim]\\[U]\n",
    "        Returns a minibatch of strings, encoded as labels and padded to have the same length.\n",
    "        \"\"\"\n",
    "        x = []; y = []\n",
    "        batch_size = len(batch)\n",
    "        for index in range(batch_size):\n",
    "            x_,y_ = batch[index]\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "\n",
    "    # pad all sequences to have same length\n",
    "        T = [len(x_) for x_ in x]\n",
    "        U = [len(y_) for y_ in y]\n",
    "        T_max = max(T)\n",
    "        U_max = max(U)\n",
    "        for index in range(batch_size):\n",
    "            x[index] = torch.cat((torch.tensor([[NULL_INDEX] * 40 ] * (T_max - len(x[index]))),x[index]),dim = 0)\n",
    "            y[index] = torch.cat((torch.tensor([NULL_INDEX] * (U_max - len(y[index]))), y[index]),dim = 0)\n",
    "\n",
    "        # stack into single tensor\n",
    "        x = torch.stack(x)\n",
    "        y = torch.stack(y).long()\n",
    "        T = torch.tensor(T)\n",
    "        U = torch.tensor(U)\n",
    "\n",
    "        return (x,y,T,U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e3e398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, lr):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=self.lr)\n",
    "  \n",
    "    def train(self, dataset, print_interval = 20):\n",
    "        train_loss = 0\n",
    "        num_samples = 0 \n",
    "        self.model.train()\n",
    "        pbar = tqdm(dataset.loader)\n",
    "        for idx, batch in enumerate(pbar):\n",
    "            x,y,T,U = batch\n",
    "            x = x.to(self.model.device)\n",
    "            y = y.to(self.model.device)\n",
    "            T = T.to(self.model.device)\n",
    "            U = U.to(self.model.device)\n",
    "            batch_size = len(x)\n",
    "            num_samples += batch_size\n",
    "            #loss = self.model.compute_loss1(x,y,torch.ceil(T/4).long(),U,0)\n",
    "            loss = self.model.compute_loss1(x,y,torch.ceil(T/4).long(),U)\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                pbar.set_description(\"%.2f\" % loss.item())\n",
    "                train_loss += loss.item() * batch_size\n",
    "                #if idx % print_interval == 0:\n",
    "                #    #self.model.eval()\n",
    "                #    guesses = self.model.greedy_search(x,T)\n",
    "                #   #self.model.train()\n",
    "                #    print(\"\\n\")\n",
    "                #    for b in range(2):\n",
    "                #        print(\"guess:\", guesses[b])\n",
    "                #        print(\"truth:\", y[b,:U[b]])\n",
    "                #        print(\"\")\n",
    "                train_loss /= num_samples\n",
    "        return train_loss\n",
    "\n",
    "    def test(self, dataset, print_interval=20):\n",
    "        test_loss = 0\n",
    "        num_samples = 0\n",
    "        self.model.eval()\n",
    "        pbar = tqdm(dataset.loader)\n",
    "        for idx, batch in enumerate(pbar):\n",
    "            x,y,T,U = batch\n",
    "            x = x.to(self.model.device)\n",
    "            y = y.to(self.model.device)\n",
    "            T = T.to(self.model.device)\n",
    "            U = U.to(self.model.device)\n",
    "            batch_size = len(x)\n",
    "            num_samples += batch_size\n",
    "            loss = self.model.compute_loss(x,y,torch.ceil(T/4).long(),U,0)\n",
    "            pbar.set_description(\"%.2f\" % loss.item())\n",
    "            test_loss += loss.item() * batch_size\n",
    "            if idx % print_interval == 0:\n",
    "                print(\"\\n\")\n",
    "                print(\"guess:\", self.model.greedy_search(x,T)[0])\n",
    "                print(\"truth:\", y[0,:U[0]])\n",
    "                print(\"\")\n",
    "        test_loss /= num_samples\n",
    "        return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f2a8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.76: 100%|█████████████████████████████████████████████████████████████████████████▋| 285/286 [02:45<00:00,  1.99it/s]C:\\Users\\wangkengxue\\AppData\\Roaming\\Python\\Python38\\site-packages\\numba\\cuda\\compiler.py:865: NumbaPerformanceWarning: \u001b[1mGrid size (3) < 2 * SM count (28) will likely result in GPU under utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "0.14: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n",
      "0.08: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n",
      "0.05: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n",
      "0.03: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n",
      "0.03: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.72it/s]\n",
      "0.02: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n",
      "0.02: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n",
      "0.02: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n",
      "0.01: 100%|██████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n",
      "-0.01: 100%|█████████████████████████████████████████████████████████████████████████| 286/286 [02:45<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "end_length = int(0.1 * len(speech_sets))\n",
    "train_sets = SpeechDataset(speech_sets[:end_length],text_sets[:end_length],batch_size = 10)\n",
    "tranducer = Transducer(embed_size = 40, encoder_dim = 100, num_layers = 1, dropout  = 0, \n",
    "                       num_outputs = 29, predictor_dim = 100, joiner_dim = 100, NULL_INDEX = 0)\n",
    "tranducer.load_state_dict(torch.load('./tranducer.pth'))\n",
    "trainer = Trainer(model=tranducer, lr=0.003)\n",
    "num_epochs = 10\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = trainer.train(train_sets)\n",
    "    #test_loss = trainer.test(train_sets)\n",
    "    train_losses.append(train_loss)\n",
    "    #test_losses.append(test_loss)\n",
    "    print(\"Epoch %d: train loss = %f, test loss = null\" % (epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b09b00f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tranducer.state_dict(),'./tranducer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa79d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l(python3.8)",
   "language": "python",
   "name": "dl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
